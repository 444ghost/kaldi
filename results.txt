for x in exp/*/decode*; do [ -d $x ] && grep WER $x/wer_* | utils/best_wer.sh; done


nj	cmvn	wavelet	transform	feats	J/zoom	dithering	x^2_windowing	window	shift	details:				mono/tri	

default	yes	-	Fourier/DCT	13	-	yes		yes		25ms	10ms	MFCCs					0.9/0.64
default	yes	-	Fourier/DCT	50	-	yes		yes		25ms	10ms	MFCCs					3.24/2.48

default	--fake	haar	dwt		24	7	no		no		25ms	10ms	max, min, L2 norm subband		10.60/7.11
default	--fake	haar	dwt		24	7	no		no		40ms	10ms	max, min, L2 norm subband		10.04/6.81
default	--fake	haar	dwt		24	7	no		no		40ms	15ms	max, min, L2 norm subband		9.11/5.31
default	--fake	haar	dwt		24	7	no		no		40ms	20ms	max, min, L2 norm subband		9.49/5.90
default	--fake	haar	dwt		24	7	no		no		50ms	10ms	max, min, L2 norm subband		9.47/6.67
default	--fake	haar	dwt		24	7	no		no		50ms	15ms	max, min, L2 norm subband		9.32/5.82
default	--fake	haar	dwt		24	7	no		no		50ms	20ms	max, min, L2 norm subband		8.75/5.49
default --fake	haar	dwt		27	8	no		no		50ms	20ms	max, min, L2 norm subband		9.21/5.81

default	--fake	db4	dwt		24	7	no		no		40ms	15ms	max, min, L2 norm subband		7.13/4.18
default	--fake	db4	dwt		16	7	no		no		40ms	15ms	max, L2 norm subband			6.33/3.74
default	--fake	db4	dwt		16	7	no		no		40ms	15ms	max, L2 norm subband/Dim()		6.15/3.72
default	--fake	db4	dwt		14	7/1	no		no		40ms	15ms	max, L2 norm subband/Dim()		6.64/4.12

default --fake	haar	wpt		14	5/2	no		no		25ms	10ms	max, 1 low max, L2 norm subband		10.63/6.94
default --fake	haar	wpt		30	5/2	no		no		40ms	15ms	max, 1 low max, L2 norm subband		10.06/6.55

default --fake	db4	wpt		30	6/2	no		no		40ms	15ms	max, 1 low max, L2 norm subband		9.41/5.97

-------------------------------------------------------------------------------------------------------------------------------------------------------------
nj	cmvn	wavelet	transform	feats	J/zoom	dithering	x^2_windowing	window	shift	details:				mono/tri	
default	--fake	db4	dwt		16	7	no		no		40ms	15ms	max, L2 norm subband/Dim()		6.15/3.72

training	--splice-width		--num-hidden-layers	--initial-learning-rate		--num-epochs		WER
raw/lda		--mini-batch-size	--hidden-layer-dim	--final-learning-rate		--iters-per-epochs

nnet2		4			2			0.02/0.004			10			2.79
nnet2		4			2			0.02/0.004			20			2.75
nnet2		4			2			0.015/0.004			20			2.45
nnet2		4			2			0.01/0.004			20			2.15
nnet2		4			2			0.01/0.002			20			2.80
nnet2		4			2			0.0075/0.004			20			2.23
nnet2		4			2			0.005/0.004			20			2.30
nnet2		4			2			0.005/0.002			20			2.37
nnet2		4			2			0.04/0.004			20			5.25
nnet2		2			2			0.04/0.004			20			5.67

nnet2		4			2			0.01/0.004			20			2.15
nnet2		6			2			0.01/0.004			20			2.82
nnet2		2			2			0.01/0.004			20			2.80
nnet2		4			3			0.01/0.004			20			2.50
nnet2		4			2			0.01/0.004			20/2			2.46
nnet2		4			2/25			0.01/0.004			20			3.59
nnet2		4			2/75			0.01/0.004			20			2.21
nnet2		4			2/100			0.01/0.004			20			1.97
nnet2		4			2/200			0.01/0.004			20			1.59
nnet2		4			2/400			0.01/0.004			20			1.85
nnet2		4			2/300			0.01/0.004			20			1.54
nnet2		4			2/250			0.01/0.004			20			1.45
nnet2		4			2/225			0.01/0.004			20			1.64

nnet2		4			2/250			0.01/0.004			20			1.50
nnet2		4			3/250			0.01/0.004			20			2.81
nnet2		4			1/250			0.01/0.004			20			2.15
nnet2		4/64			2/250			0.01/0.004			20			1.55
nnet2		4/256			2/250			0.01/0.004			20			5.82
nnet2		4			2/250			0.01/0.004			20/5			1.53
